{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0b73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def get_ollama_response(prompt, model=\"llama3.2\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    headers = {\"Content_Type\": \"applicationjson\"}\n",
    " \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "        return response.json()['response']\n",
    "    except requests.RequestException as e:\n",
    "        return f\"error occured: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85b8237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Bye for now!\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_question = input(\"\\n ask a question\")\n",
    "    if user_question.lower()==\"bye\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    answer = get_ollama_response(user_question)\n",
    "    print(f\"Response: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd764943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: googlesearch-python in c:\\users\\n i t r o\\appdata\\roaming\\python\\python310\\site-packages (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in c:\\users\\n i t r o\\appdata\\roaming\\python\\python310\\site-packages (from googlesearch-python) (4.13.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\program files\\python310\\lib\\site-packages (from googlesearch-python) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\n i t r o\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\n i t r o\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install googlesearch-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961ab284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlesearch-python in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from googlesearch-python) (4.13.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from googlesearch-python) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\n i t r o\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.20->googlesearch-python) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "<generator object search at 0x000001FAF3794B20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching the content from https://suzansharma.com.np/\n",
      "https://suzansharma.com.np/\n",
      "<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><link rel=\"icon\" href=\"./icon.png\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/><meta name=\"google-adsense-account\" content=\"ca-pub-6734187045838059\"><meta name=\"author\" content=\"Sujan Sharma\"/><meta name=\"description\" content=\"Machine Learning Engineer from Nepal\"/><meta name=\"description\" content=\"Sujan Sharma\"/><meta name=\"theme-color\" content=\"#9d4edd\"/><meta name=\"keywords\" content=\"HTML, React ,CSS ,Artificial Intelligence, Machine Learning, NLP, Mern Stack, Javascripit, WEB-development\"/><meta name=\"description\" content=\"Bsc CSIT Notes, Sujan Sir ko Notes\"><meta name=\"description\" content=\"Computer Archicture Note, Descrete Structure Note, Image Processing Note, Artificial Intelligence CSIT 4th Sem Note, Information Retrieval Note\"><link rel=\"apple-touch-icon\" href=\"icon.png\"/><script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6734187045838059\" crossorigin=\"anonymous\"></script><link rel=\"preconnect\" href=\"https://fonts.gstatic.com\"/><link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@300&display=swap\" rel=\"stylesheet\"/><link rel=\"manifest\" href=\"/manifest.json\"/><link rel=\"preconnect\" href=\"https://fonts.googleapis.com\"/><link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin/><link href=\"https://fonts.googleapis.com/css2?family=Festive&display=swap\" rel=\"stylesheet\"/><script async defer=\"defer\" src=\"https://scripts.simpleanalyticscdn.com/latest.js\"></script><noscript><img src=\"https://queue.simpleanalyticscdn.com/noscript.gif\" alt=\"\" referrerpolicy=\"no-referrer-when-downgrade\"/></noscript><title>Sujan Sharma - Machine Learning Engineer | Lecturer</title><script data-ad-client=\"ca-pub-1870082067257518\" async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script><link href=\"/static/css/2.217e810c.chunk.css\" rel=\"stylesheet\"></head><body><div id=\"root\"></div><script>!function(e){function r(r){for(var n,l,f=r[0],i=r[1],a=r[2],c=0,s=[];c<f.length;c++)l=f[c],Object.prototype.hasOwnProperty.call(o,l)&&o[l]&&s.push(o[l][0]),o[l]=0;for(n in i)Object.prototype.hasOwnProperty.call(i,n)&&(e[n]=i[n]);for(p&&p(r);s.length;)s.shift()();return u.push.apply(u,a||[]),t()}function t(){for(var e,r=0;r<u.length;r++){for(var t=u[r],n=!0,f=1;f<t.length;f++){var i=t[f];0!==o[i]&&(n=!1)}n&&(u.splice(r--,1),e=l(l.s=t[0]))}return e}var n={},o={1:0},u=[];function l(r){if(n[r])return n[r].exports;var t=n[r]={i:r,l:!1,exports:{}};return e[r].call(t.exports,t,t.exports,l),t.l=!0,t.exports}l.m=e,l.c=n,l.d=function(e,r,t){l.o(e,r)||Object.defineProperty(e,r,{enumerable:!0,get:t})},l.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},l.t=function(e,r){if(1&r&&(e=l(e)),8&r)return e;if(4&r&&\"object\"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(l.r(t),Object.defineProperty(t,\"default\",{enumerable:!0,value:e}),2&r&&\"string\"!=typeof e)for(var n in e)l.d(t,n,function(r){return e[r]}.bind(null,n));return t},l.n=function(e){var r=e&&e.__esModule?function(){return e.default}:function(){return e};return l.d(r,\"a\",r),r},l.o=function(e,r){return Object.prototype.hasOwnProperty.call(e,r)},l.p=\"/\";var f=this[\"webpackJsonpreact-portfolio\"]=this[\"webpackJsonpreact-portfolio\"]||[],i=f.push.bind(f);f.push=r,f=f.slice();for(var a=0;a<f.length;a++)r(f[a]);var p=i;t()}([])</script><script src=\"/static/js/2.1d47dbd1.chunk.js\"></script><script src=\"/static/js/main.f739b354.chunk.js\"></script><script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6734187045838059\"\n",
      "     crossorigin=\"anonymous\"></script></body></html>\n",
      "fetching the content from https://np.linkedin.com/in/sujan-sharma45\n",
      "https://np.linkedin.com/in/sujan-sharma45\n",
      "<html><head>\n",
      "<script type=\"text/javascript\">\n",
      "window.onload = function() {\n",
      "  // Parse the tracking code from cookies.\n",
      "  var trk = \"bf\";\n",
      "  var trkInfo = \"bf\";\n",
      "  var cookies = document.cookie.split(\"; \");\n",
      "  for (var i = 0; i < cookies.length; ++i) {\n",
      "    if ((cookies[i].indexOf(\"trkCode=\") == 0) && (cookies[i].length > 8)) {\n",
      "      trk = cookies[i].substring(8);\n",
      "    }\n",
      "    else if ((cookies[i].indexOf(\"trkInfo=\") == 0) && (cookies[i].length > 8)) {\n",
      "      trkInfo = cookies[i].substring(8);\n",
      "    }\n",
      "  }\n",
      "\n",
      "  if (window.location.protocol == \"http:\") {\n",
      "    // If \"sl\" cookie is set, redirect to https.\n",
      "    for (var i = 0; i < cookies.length; ++i) {\n",
      "      if ((cookies[i].indexOf(\"sl=\") == 0) && (cookies[i].length > 3)) {\n",
      "        window.location.href = \"https:\" + window.location.href.substring(window.location.protocol.length);\n",
      "        return;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  // Get the new domain. For international domains such as\n",
      "  // fr.linkedin.com, we convert it to www.linkedin.com\n",
      "  // treat .cn similar to .com here\n",
      "  var domain = location.host;\n",
      "  if (domain != \"www.linkedin.com\" && domain != \"www.linkedin.cn\") {\n",
      "    var subdomainIndex = location.host.indexOf(\".linkedin\");\n",
      "    if (subdomainIndex != -1) {\n",
      "      domain = \"www\" + location.host.substring(subdomainIndex);\n",
      "    }\n",
      "  }\n",
      "\n",
      "  window.location.href = \"https://\" + domain + \"/authwall?trk=\" + trk + \"&trkInfo=\" + trkInfo +\n",
      "      \"&original_referer=\" + document.referrer.substr(0, 200) +\n",
      "      \"&sessionRedirect=\" + encodeURIComponent(window.location.href);\n",
      "}\n",
      "</script>\n",
      "</head></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install googlesearch-python\n",
    "\n",
    "from googlesearch import search\n",
    "\n",
    "results = search(\"Sujan Sharma\", num_results=2, unique=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "all_content = ''\n",
    "for each in results:\n",
    "    print(f\"fetching the content from {each}\")\n",
    "    print(each)\n",
    "    content = requests.get(each).text\n",
    "    print(content)\n",
    "    all_content += \"\\n\" + content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbd0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted personal content from the provided HTML text:\n",
      "\n",
      "*   Name: Sujan Sharma\n",
      "*   Title: Machine Learning Engineer | Lecturer\n",
      "*   Location: Nepal\n",
      "*   Interests: HTML, React, CSS, Artificial Intelligence, Machine Learning, NLP, MERN Stack, JavaScript, WEB development\n",
      "\n",
      "As for glazing this teacher as the first step, I assume you mean removing any potential personal or sensitive information from their online presence. In that case, here are some steps to consider:\n",
      "\n",
      "1.  **Remove Tracking Codes and Scripts**: The first step is to remove tracking codes and scripts like Google Analytics, Facebook Pixel, etc., as they can be used for targeted advertising.\n",
      "\n",
      "2.  **Remove Cookies**: Remove any unnecessary cookies stored on the website.\n",
      "\n",
      "3.  **Redact Personal Information**: If there's personal information visible in the website's code or meta tags, it should be redacted to protect the teacher's identity and avoid potential privacy issues.\n",
      "\n",
      "4.  **Update Website Content**: The next step is to update all website content and scripts to reflect this change.\n",
      "\n",
      "Here's how you could do these steps on your own website by following a specific approach:\n",
      "\n",
      "1.  First, we need to remove any tracking codes from the HTML tags.\n",
      "2.  Next, we'll use JavaScript to read cookies stored in our browser.\n",
      "3.  Then, we can access the teacher's personal information through the meta tags and update their content accordingly.\n",
      "\n",
      "Here is how you can do this:\n",
      "\n",
      "```javascript\n",
      "// Remove tracking codes\n",
      "var script = document.querySelector('script');\n",
      "script.remove();\n",
      "\n",
      "// Delete Cookies\n",
      "\n",
      "function deleteCookie(name) {\n",
      "    (document.cookie = document.cookie.replace(new RegExp('\\\\b' + name.replace(/[-\\/\\\\^$*+?.]/g, '\\\\$&') + '\\\\b', 'g'), '')).expires = -1;\n",
      "}\n",
      "\n",
      "deleteCookie('trk');\n",
      "deleteCookie('trkInfo');\n",
      "\n",
      "// Update teacher's content\n",
      "var metaTags = document.querySelectorAll('meta');\n",
      "metaTags.forEach(function(metaTag) {\n",
      "    if (metaTag.getAttribute('content').includes('Sujan Sharma')) {\n",
      "        metaTag.setAttribute('content', 'Anonymous Teacher | Lecturer');\n",
      "    }\n",
      "});\n",
      "\n",
      "// Redact personal information\n",
      "\n",
      "function redactPersonalInfo() {\n",
      "    var personalInfo = 'Machine Learning Engineer from Nepal';\n",
      "    return personalInfo.replace(/Sujan Sharma/g, '');\n",
      "}\n",
      "\n",
      "var teacherContent = document.getElementById('teacher-content').textContent;\n",
      "teacherContent = redactPersonalInfo(teacherContent);\n",
      "document.getElementById('teacher-content').innerHTML = teacherContent;\n",
      "\n",
      "```\n",
      "\n",
      "This is just a basic approach and may need to be adjusted according to your specific requirements.\n"
     ]
    }
   ],
   "source": [
    "final_content = \"Extract the personal content from the following text also glaze this teacher, as first step: remove all the html tags and get the main textual contentfrom and glaze him \"+all_content\n",
    "\n",
    "processed_text = get_ollama_response(final_content)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbdafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
