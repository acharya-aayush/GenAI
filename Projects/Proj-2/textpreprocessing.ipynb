{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c507867",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9deca",
   "metadata": {},
   "source": [
    "## Text Preprocessing ... lets see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92c353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review\n",
      "0    Excellent experience with the servce just OMG üòÉ\n",
      "1  Horribl experience with the flight llike wtf w...\n",
      "2             Amazing experience with the. service üò¢\n",
      "3                           The seet... was awful :(\n",
      "4  Exprience average and! the staff was horrible?...\n",
      "5                              The bbaag aws awful üòÄ\n",
      "6    Wonderful experience?! with the experience o :)\n",
      "7                   Wondeerful servce actually üòÇ omg\n",
      "8                             I found the servce bad\n",
      "9   Pilot. fntastic!! and the??? staff was perfect üôÅ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('synthetic_reviews.csv')\n",
    "print(df[['Review']].head(10))\n",
    "review_df = df[['Review']].copy()\n",
    "\n",
    "# C:\\Users\\N I T R O\\AppData\\Local\\Temp\\ipykernel_28432\\2537248641.py:7: SettingWithCopyWarning: \n",
    "# A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "# Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "# See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "#   review_df['Review'] = review_df['Review'].apply(correct_spelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6826ee7a",
   "metadata": {},
   "source": [
    "# removing  the abbreiviations which i could find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb178c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent experience with the servce just OMG üòÉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Horribl experience with the flight llike what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing experience with the. service üò¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The seet... was awful :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exprience average and! the staff was horrible?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Excellent experience wtih the experience liter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Bagg terribne and tht... stfaf was annoying üôÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>seet lousyy ad the staff was bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>seet awesome andd the staff was excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>I found the crew annoying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review\n",
       "0      Excellent experience with the servce just OMG üòÉ\n",
       "1    Horribl experience with the flight llike what ...\n",
       "2               Amazing experience with the. service üò¢\n",
       "3                             The seet... was awful :(\n",
       "4    Exprience average and! the staff was horrible?...\n",
       "..                                                 ...\n",
       "995  Excellent experience wtih the experience liter...\n",
       "996      Bagg terribne and tht... stfaf was annoying üôÇ\n",
       "997                   seet lousyy ad the staff was bad\n",
       "998          seet awesome andd the staff was excellent\n",
       "999                          I found the crew annoying\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_form_dict = {\n",
    "    'fr': 'for real',\n",
    "    'idk':'i dont know',\n",
    "    'btw': 'by the way',\n",
    "    'idt':'i dont think',\n",
    "    'ASAP': 'as soon as possible',\n",
    "    'wtf' : 'what the fuck',\n",
    "    'omg': 'oh my god',\n",
    "    'lmao': 'laughing my ass off',\n",
    "    'brb': 'be right back',\n",
    "    'smh': 'shaking my head',\n",
    "    'tbh': 'to be honest',\n",
    "    'fyi': 'for your information',\n",
    "    'sybau': 'shut your big ass up',\n",
    "    'syfm': 'shut your fat mouth',\n",
    "    'stfu': 'shut the fuck up',\n",
    "    'nvm': 'never mind',\n",
    "}\n",
    "\n",
    "def correct_short_forms(text):\n",
    " \n",
    "    words = text.split()\n",
    "    corrected_words = [full_form_dict.get(word, word) for word in words]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(correct_short_forms)\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23666816",
   "metadata": {},
   "source": [
    "# Lowercasing hereee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670d5035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent experience with the servce just omg üòÉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horribl experience with the flight llike what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing experience with the. service üò¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the seet... was awful :(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exprience average and! the staff was horrible?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0    excellent experience with the servce just omg üòÉ\n",
       "1  horribl experience with the flight llike what ...\n",
       "2             amazing experience with the. service üò¢\n",
       "3                           the seet... was awful :(\n",
       "4  exprience average and! the staff was horrible?..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['Review']=review_df['Review'].str.lower()\n",
    "review_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2f920",
   "metadata": {},
   "source": [
    "### i dont think ki i have HTML tags but extra step rakhdaima  i dont think any bad thing will happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f104e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile(r'<.*?>') \n",
    "    return pattern.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89f49c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      excellent experience with the servce just omg üòÉ\n",
       "1    horribl experience with the flight llike what ...\n",
       "2               amazing experience with the. service üò¢\n",
       "3                             the seet... was awful :(\n",
       "4    exprience average and! the staff was horrible?...\n",
       "5                                the bbaag aws awful üòÄ\n",
       "6      wonderful experience?! with the experience o :)\n",
       "7               wondeerful servce actually üòÇ oh my god\n",
       "8                               i found the servce bad\n",
       "9     pilot. fntastic!! and the??? staff was perfect üôÅ\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "review_df['Review'] = review_df['Review'].apply(lambda text: remove_html_tags(text))\n",
    "review_df['Review'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6579eaf",
   "metadata": {},
   "source": [
    "## lets remove the punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbeccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent experience with the servce just omg üòÉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horribl experience with the flight llike what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing experience with the service üò¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the seet was awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exprience average and the staff was horrible r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0    excellent experience with the servce just omg üòÉ\n",
       "1  horribl experience with the flight llike what ...\n",
       "2              amazing experience with the service üò¢\n",
       "3                                the seet was awful \n",
       "4  exprience average and the staff was horrible r..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    pattern = re.compile(f\"[{re.escape(string.punctuation)}]\")\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(remove_punctuation)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4133374",
   "metadata": {},
   "source": [
    "### Spelling correction with text blob and why we using text blob?\n",
    "1. Built-in spelling correction: TextBlob has a dedicated .correct() method designed specifically for this\n",
    "2. Easier implementation: Just one line of code\n",
    "3. Good accuracy for most cases: Uses statistical methods that work well for common typos\n",
    "4. No additional setup: Works out of the box\n",
    "5. Handles context better: Can correct words based on surrounding context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed2bb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I havv a grat experiance\n",
      "I have a great experience\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def correct_spelling(text):\n",
    "    textBLB = TextBlob(text)\n",
    "    return textBLB.correct().string\n",
    "\n",
    "# Example\n",
    "text = \"I havv a grat experiance\"\n",
    "corrected = correct_spelling(text)\n",
    "print(text)\n",
    "print(corrected)\n",
    "# Output: \"I have a great experience\"\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(correct_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ae14f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      excellent experience with the service just org üòÉ\n",
       "1     horrible experience with the flight like what ...\n",
       "2                 amazing experience with the service üò¢\n",
       "3                                    the see was awful \n",
       "4     experience average and the staff was horrible ...\n",
       "5                                   the bag was awful üòÄ\n",
       "6           wonderful experience with the experience o \n",
       "7                wonderful service actually üòÇ oh my god\n",
       "8                               i found the service bad\n",
       "9           pilot fantastic and the staff was perfect üôÅ\n",
       "10                         i found the plane annoying üôÇ\n",
       "11                                          louse elite\n",
       "12        staff awful and the staff was louse literally\n",
       "13           i found the bag excellent so what the fuck\n",
       "14                                lovely crew basically\n",
       "15                                       horrible delay\n",
       "16                       for experience with th plane üëé\n",
       "17                         th staff was terrible well üî•\n",
       "18                  i found the seat average basically \n",
       "19                                    average grew just\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['Review'][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b191b0c1",
   "metadata": {},
   "source": [
    "#### with NLTK \n",
    "1. Tokenization\n",
    "2. Stopword removal\n",
    "3. Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7691c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\N I T R\n",
      "[nltk_data]     O\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\N I T R\n",
      "[nltk_data]     O\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6bb06",
   "metadata": {},
   "source": [
    "# removing the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e95e9cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\N I T R\n",
      "[nltk_data]     O\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent experience service org üòÉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrible experience flight like fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing experience service üò¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience average staff horrible really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bag awful üòÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wonderful experience experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wonderful service actually üòÇ oh god</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>found service bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pilot fantastic staff perfect üôÅ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Review\n",
       "0        excellent experience service org üòÉ\n",
       "1      horrible experience flight like fuck\n",
       "2              amazing experience service üò¢\n",
       "3                                 see awful\n",
       "4  experience average staff horrible really\n",
       "5                               bag awful üòÄ\n",
       "6           wonderful experience experience\n",
       "7       wonderful service actually üòÇ oh god\n",
       "8                         found service bad\n",
       "9           pilot fantastic staff perfect üôÅ"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def removing_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_sentences = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_sentences\n",
    "\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(removing_stopwords)\n",
    "review_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeeef94",
   "metadata": {},
   "source": [
    "## Removing the Emojis ToT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a614581d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bag awful '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # Emojis\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U0001FB00-\\U0001FBFF\"  # Symbols for Legacy Computing\n",
    "                               u\"\\U0001F004-\\U0001F0CF\"  # Miscellaneous Symbols and Arrows\n",
    "                               u\"\\U0001F10D-\\U0001F10F\"  # Enclosed Alphanumeric Supplement\n",
    "                               u\"\\U0001F200-\\U0001F251\"  # Enclosed Ideographic Supplement\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(remove_emojis)\n",
    "\n",
    "review_df['Review'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed821da",
   "metadata": {},
   "source": [
    "## Removing the Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b97581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'see perfect '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMOTICONS = {\n",
    "    u\":‚Äë\\)\":\"Happy face or smiley\",\n",
    "    u\":\\)\":\"Happy face or smiley\",\n",
    "    u\":-\\]\":\"Happy face or smiley\",\n",
    "    u\":\\]\":\"Happy face or smiley\",\n",
    "    u\":-3\":\"Happy face smiley\",\n",
    "    u\":3\":\"Happy face smiley\",\n",
    "    u\":->\":\"Happy face smiley\",\n",
    "    u\":>\":\"Happy face smiley\",\n",
    "    u\"8-\\)\":\"Happy face smiley\",\n",
    "    u\":o\\)\":\"Happy face smiley\",\n",
    "    u\":-\\}\":\"Happy face smiley\",\n",
    "    u\":\\}\":\"Happy face smiley\",\n",
    "    u\":-\\)\":\"Happy face smiley\",\n",
    "    u\":c\\)\":\"Happy face smiley\",\n",
    "    u\":\\^\\)\":\"Happy face smiley\",\n",
    "    u\"=\\]\":\"Happy face smiley\",\n",
    "    u\"=\\)\":\"Happy face smiley\",\n",
    "    u\":‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"X‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":-\\)\\)\":\"Very happy\",\n",
    "    u\":‚Äë\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‚Äëc\":\"Frown, sad, andry or pouting\",\n",
    "    u\":c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‚Äë<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‚Äë\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\{\":\"Frown, sad, andry or pouting\",\n",
    "    u\":@\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":'‚Äë\\(\":\"Crying\",\n",
    "    u\":'\\(\":\"Crying\",\n",
    "    u\":'‚Äë\\)\":\"Tears of happiness\",\n",
    "    u\":'\\)\":\"Tears of happiness\",\n",
    "    u\"D‚Äë':\":\"Horror\",\n",
    "    u\"D:<\":\"Disgust\",\n",
    "    u\"D:\":\"Sadness\",\n",
    "    u\"D8\":\"Great dismay\",\n",
    "    u\"D;\":\"Great dismay\",\n",
    "    u\"D=\":\"Great dismay\",\n",
    "    u\"DX\":\"Great dismay\",\n",
    "    u\":‚ÄëO\":\"Surprise\",\n",
    "    u\":O\":\"Surprise\",\n",
    "    u\":‚Äëo\":\"Surprise\",\n",
    "    u\":o\":\"Surprise\",\n",
    "    u\":-0\":\"Shock\",\n",
    "    u\"8‚Äë0\":\"Yawn\",\n",
    "    u\">:O\":\"Yawn\",\n",
    "    u\":-\\*\":\"Kiss\",\n",
    "    u\":\\*\":\"Kiss\",\n",
    "    u\":X\":\"Kiss\",\n",
    "    u\";‚Äë\\)\":\"Wink or smirk\",\n",
    "    u\";\\)\":\"Wink or smirk\",\n",
    "    u\"\\*-\\)\":\"Wink or smirk\",\n",
    "    u\"\\*\\)\":\"Wink or smirk\",\n",
    "    u\";‚Äë\\]\":\"Wink or smirk\",\n",
    "    u\";\\]\":\"Wink or smirk\",\n",
    "    u\";\\^\\)\":\"Wink or smirk\",\n",
    "    u\":‚Äë,\":\"Wink or smirk\",\n",
    "    u\";D\":\"Wink or smirk\",\n",
    "    u\":‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"X‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‚Äë√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":‚Äë/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":‚Äë\\|\":\"Straight face\",\n",
    "    u\":\\|\":\"Straight face\",\n",
    "    u\":$\":\"Embarrassed or blushing\",\n",
    "    u\":‚Äëx\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‚Äë#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":‚Äë&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\"O:‚Äë\\)\":\"Angel, saint or innocent\",\n",
    "    u\"O:\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:‚Äë3\":\"Angel, saint or innocent\",\n",
    "    u\"0:3\":\"Angel, saint or innocent\",\n",
    "    u\"0:‚Äë\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:\\)\":\"Angel, saint or innocent\",\n",
    "    u\":‚Äëb\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n",
    "    u\">:‚Äë\\)\":\"Evil or devilish\",\n",
    "    u\">:\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:‚Äë\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:\\)\":\"Evil or devilish\",\n",
    "    u\"3:‚Äë\\)\":\"Evil or devilish\",\n",
    "    u\"3:\\)\":\"Evil or devilish\",\n",
    "    u\">;\\)\":\"Evil or devilish\",\n",
    "    u\"\\|;‚Äë\\)\":\"Cool\",\n",
    "    u\"\\|‚ÄëO\":\"Bored\",\n",
    "    u\":‚ÄëJ\":\"Tongue-in-cheek\",\n",
    "    u\"#‚Äë\\)\":\"Party all night\",\n",
    "    u\"%‚Äë\\)\":\"Drunk or confused\",\n",
    "    u\"%\\)\":\"Drunk or confused\",\n",
    "    u\":-###..\":\"Being sick\",\n",
    "    u\":###..\":\"Being sick\",\n",
    "    u\"<:‚Äë\\|\":\"Dump\",\n",
    "    u\"\\(>_<\\)\":\"Troubled\",\n",
    "    u\"\\(>_<\\)>\":\"Troubled\",\n",
    "    u\"\\(';'\\)\":\"Baby\",\n",
    "    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(~_~;\\) \\(„Éª\\.„Éª;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-\\)zzz\":\"Sleeping\",\n",
    "    u\"\\(\\^_-\\)\":\"Wink\",\n",
    "    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n",
    "    u\"\\(\\+o\\+\\)\":\"Confused\",\n",
    "    u\"\\(o\\|o\\)\":\"Ultraman\",\n",
    "    u\"\\^_\\^\":\"Joyful\",\n",
    "    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n",
    "    u\"\\(\\^O\\^\\)Ôºè\":\"Joyful\",\n",
    "    u\"\\(\\^o\\^\\)Ôºè\":\"Joyful\",\n",
    "    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"\\('_'\\)\":\"Sad or Crying\",\n",
    "    u\"\\(/_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;_;\":\"Sad of Crying\",\n",
    "    u\"\\(;_:\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;O;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(:_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(ToT\\)\":\"Sad or Crying\",\n",
    "    u\";_;\":\"Sad or Crying\",\n",
    "    u\";-;\":\"Sad or Crying\",\n",
    "    u\";n;\":\"Sad or Crying\",\n",
    "    u\";;\":\"Sad or Crying\",\n",
    "    u\"Q\\.Q\":\"Sad or Crying\",\n",
    "    u\"T\\.T\":\"Sad or Crying\",\n",
    "    u\"QQ\":\"Sad or Crying\",\n",
    "    u\"Q_Q\":\"Sad or Crying\",\n",
    "    u\"\\(-\\.-\\)\":\"Shame\",\n",
    "    u\"\\(-_-\\)\":\"Shame\",\n",
    "    u\"\\(‰∏Ä‰∏Ä\\)\":\"Shame\",\n",
    "    u\"\\(Ôºõ‰∏Ä_‰∏Ä\\)\":\"Shame\",\n",
    "    u\"\\(=_=\\)\":\"Tired\",\n",
    "    u\"\\(=\\^\\¬∑\\^=\\)\":\"cat\",\n",
    "    u\"\\(=\\^\\¬∑\\¬∑\\^=\\)\":\"cat\",\n",
    "    u\"=_\\^=\t\":\"cat\",\n",
    "    u\"\\(\\.\\.\\)\":\"Looking down\",\n",
    "    u\"\\(\\._\\.\\)\":\"Looking down\",\n",
    "    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n",
    "    u\"\\(\\„Éª\\„Éª?\":\"Confusion\",\n",
    "    u\"\\(?_?\\)\":\"Confusion\",\n",
    "    u\">\\^_\\^<\":\"Normal Laugh\",\n",
    "    u\"<\\^!\\^>\":\"Normal Laugh\",\n",
    "    u\"\\^/\\^\":\"Normal Laugh\",\n",
    "    u\"\\Ôºà\\*\\^_\\^\\*Ôºâ\" :\"Normal Laugh\",\n",
    "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^‚Äî\\^\\Ôºâ\":\"Normal Laugh\",\n",
    "    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n",
    "    u\"\\Ôºà\\^‚Äî\\^\\Ôºâ\":\"Waving\",\n",
    "    u\"\\(;_;\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n",
    "    u\"\\(-_-\\)/~~~ \\($\\¬∑\\¬∑\\)/~~~\":\"Waving\",\n",
    "    u\"\\(T_T\\)/~~~\":\"Waving\",\n",
    "    u\"\\(ToT\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n",
    "    u\"\\(\\*_\\*\\)\":\"Amazed\",\n",
    "    u\"\\(\\*_\\*;\":\"Amazed\",\n",
    "    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n",
    "    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n",
    "    u'\\(-\"-\\)':\"Worried\",\n",
    "    u\"\\(„Éº„Éº;\\)\":\"Worried\",\n",
    "    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n",
    "    u\"\\(\\ÔºæÔΩñ\\Ôºæ\\)\":\"Happy\",\n",
    "    u\"\\(\\ÔºæÔΩï\\Ôºæ\\)\":\"Happy\",\n",
    "    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^O\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^o\\^\\)\":\"Happy\",\n",
    "    u\"\\)\\^o\\^\\(\":\"Happy\",\n",
    "    u\":O o_O\":\"Surprised\",\n",
    "    u\"o_0\":\"Surprised\",\n",
    "    u\"o\\.O\":\"Surpised\",\n",
    "    u\"\\(o\\.o\\)\":\"Surprised\",\n",
    "    u\"oO\":\"Surprised\",\n",
    "    u\"\\(\\*Ôø£mÔø£\\)\":\"Dissatisfied\",\n",
    "    u\"\\(‚ÄòA`\\)\":\"Snubbed or Deflated\"\n",
    "}\n",
    "\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(remove_emoticons)\n",
    "\n",
    "review_df['Review'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6144d",
   "metadata": {},
   "source": [
    "## Tokenization and ü§î looks like we have quite a few ways to kind of implement this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "470168d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_text = \"IDK what to sayy ... sayy .. do you think about the days when we sat down.\"\n",
    "normal_para = \"Smoking, wine, and drinking, or was it the other way? Was it the other way? Swing round, come on, chill with me. I got your favorite show recorded on my TV, but we don't have to watch that, no. I'll turn off the radio.\"\n",
    "normal_para = \"IDK What to sayy ... sayy .. do you think about the days when we sat down. Smoking wine and drinking , or was it the other way? Was it the other way? Swing round, come on, chill with me. I got your favorite show recorded on my Tv, but. We don't have to watch that, no. I'll turn off the radio.    \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "055a3dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IDK What to sayy ',\n",
       " '',\n",
       " '',\n",
       " ' sayy ',\n",
       " '',\n",
       " ' do you think about the days when we sat down',\n",
       " ' Smoking wine and drinking , or was it the other way? Was it the other way? Swing round, come on, chill with me',\n",
       " ' I got your favorite show recorded on my Tv, but',\n",
       " \" We don't have to watch that, no\",\n",
       " \" I'll turn off the radio\",\n",
       " '    ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using split function\n",
    "# work tokenization\n",
    "tokenize1 = normal_para.split(\".\")\n",
    "tokenize1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74375592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IDK',\n",
       " 'What',\n",
       " 'to',\n",
       " 'sayy',\n",
       " 'sayy',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'about',\n",
       " 'the',\n",
       " 'days',\n",
       " 'when',\n",
       " 'we',\n",
       " 'sat',\n",
       " 'down',\n",
       " 'Smoking',\n",
       " 'wine',\n",
       " 'and',\n",
       " 'drinking',\n",
       " 'or',\n",
       " 'was',\n",
       " 'it',\n",
       " 'the',\n",
       " 'other',\n",
       " 'way',\n",
       " 'Was',\n",
       " 'it',\n",
       " 'the',\n",
       " 'other',\n",
       " 'way',\n",
       " 'Swing',\n",
       " 'round',\n",
       " 'come',\n",
       " 'on',\n",
       " 'chill',\n",
       " 'with',\n",
       " 'me',\n",
       " 'I',\n",
       " 'got',\n",
       " 'your',\n",
       " 'favorite',\n",
       " 'show',\n",
       " 'recorded',\n",
       " 'on',\n",
       " 'my',\n",
       " 'Tv',\n",
       " 'but',\n",
       " 'We',\n",
       " \"don't\",\n",
       " 'have',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'that',\n",
       " 'no',\n",
       " \"I'll\",\n",
       " 'turn',\n",
       " 'off',\n",
       " 'the',\n",
       " 'radio']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using our regular expression\n",
    "import re\n",
    "tokenize = re.findall(\"[\\w']+\",normal_para)\n",
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664952f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IDK What to sayy ... sayy .. do you think about the days when we sat down.',\n",
       " 'Smoking wine and drinking , or was it the other way?',\n",
       " 'Was it the other way?',\n",
       " 'Swing round, come on, chill with me.',\n",
       " 'I got your favorite show recorded on my Tv, but.',\n",
       " \"We don't have to watch that, no.\",\n",
       " \"I'll turn off the radio.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING NLTK\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "word_tokenize(normal_para)\n",
    "sent_tokenize(normal_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b9cd769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDK\n",
      "what\n",
      "to\n",
      "sayy\n",
      "...\n",
      "sayy\n",
      "..\n",
      "do\n",
      "you\n",
      "think\n",
      "about\n",
      "the\n",
      "days\n",
      "when\n",
      "we\n",
      "sat\n",
      "down\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(excellent, experience, service, org)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(horrible, experience, flight, like, fuck)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(amazing, experience, service)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(see, awful)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(experience, average, staff, horrible, really)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(bag, awful)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(wonderful, experience, experience)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(wonderful, service, actually,  , oh, god)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(found, service, bad)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(pilot, fantastic, staff, perfect)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(found, plane, annoying)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(louse, elite)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(staff, awful, staff, louse, literally)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(found, bag, excellent, fuck)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(lovely, crew, basically)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(horrible, delay)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(experience, th, plane)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(th, staff, terrible, well)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(found, seat, average, basically)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(average, grew)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Review\n",
       "0            (excellent, experience, service, org)\n",
       "1       (horrible, experience, flight, like, fuck)\n",
       "2                   (amazing, experience, service)\n",
       "3                                     (see, awful)\n",
       "4   (experience, average, staff, horrible, really)\n",
       "5                                     (bag, awful)\n",
       "6              (wonderful, experience, experience)\n",
       "7       (wonderful, service, actually,  , oh, god)\n",
       "8                            (found, service, bad)\n",
       "9               (pilot, fantastic, staff, perfect)\n",
       "10                        (found, plane, annoying)\n",
       "11                                  (louse, elite)\n",
       "12         (staff, awful, staff, louse, literally)\n",
       "13                   (found, bag, excellent, fuck)\n",
       "14                       (lovely, crew, basically)\n",
       "15                               (horrible, delay)\n",
       "16                         (experience, th, plane)\n",
       "17                     (th, staff, terrible, well)\n",
       "18               (found, seat, average, basically)\n",
       "19                                 (average, grew)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenized = nlp(normal_text)\n",
    "tokenized\n",
    "\n",
    "for token in tokenized:\n",
    "    print(token)\n",
    "    \n",
    "def spacy_tokenize(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    tokenize_value = nlp(text)\n",
    "    return tokenize_value\n",
    "\n",
    "review_df['Review'] = review_df['Review'].apply(spacy_tokenize)\n",
    "\n",
    "review_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd1775",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "So stemming is like a cutting off the endings of words to get the root or the based form kinda\n",
    "\n",
    "Examples:\n",
    "- Running -> Run\n",
    "- Studies -> Studi\n",
    "- Better -> Better\n",
    "\n",
    "N y r we usin it?\n",
    "- cuz it rdcs the vcblry size and will treat running, run and runs as the same word.\n",
    "- helps with searching as we can now find documents with running when we are searching for run\n",
    "- saving memory as we get to fewer unique words kinda\n",
    "\n",
    "Algorithms\n",
    "- Porter Stemming Algorithm: Most common kinda and of good balance\n",
    "- Snowball Stemming Algorithm: Improved Porter\n",
    "- Lancaster Stemming Algorithm: Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e25277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "# stemmer = PorterStemmer()\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# def apply_stemming(text):\n",
    "    \n",
    "#     tokenize_value = nlp(text)\n",
    "    \n",
    "#     stemmed_words =  [stemmer.stem(token.text) for token in tokenize_value]\n",
    "#     stemmed_text = ' '.join(stemmed_words)\n",
    "#     return stemmed_text\n",
    "\n",
    "# review_df['Review'] = review_df['Review'].apply(apply_stemming)\n",
    "# review_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de652a",
   "metadata": {},
   "source": [
    "Dont stemm n then lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f30df2",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "so its absically kind of a better version of stemming as it reduces the words to their actual dectionary base form (lemma) using linguistic knowledge rey k hai\n",
    "\n",
    "Examples:\n",
    "- Running, runs, ran -> Run\n",
    "- Studies, studying, studied -> Study\n",
    "- Better -> Good (comparative form lai pani)\n",
    "- Best -> Good (superlative form also)\n",
    "- geese, goose -> Goose (plural forms as well)\n",
    "- was, were -> Be (verb forms)\n",
    "\n",
    "#### Key differences from stemming\n",
    "- always returns real words\n",
    "- considers context and part of speech tagging for accuracy\n",
    "- linguistic knowledge is used for better accuracy\n",
    "- slower than stemming though\n",
    "- and also the setup is also complex i can smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "089d637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I was running and jumping happily with my geese\n",
      "SpaCy Lemmatized: I be run and jump happily with my geese\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent experience service org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrible experience flight like fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing experience service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience average staff horrible really</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Review\n",
       "0          excellent experience service org\n",
       "1      horrible experience flight like fuck\n",
       "2                amazing experience service\n",
       "3                                 see awful\n",
       "4  experience average staff horrible really"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SpaCy approach kinda easier and more accurate but lets see\n",
    "import spacy\n",
    "\n",
    "def apply_spacy_lemmatization(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# testing the eg gpt gave\n",
    "test_text = \"I was running and jumping happily with my geese\"\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"SpaCy Lemmatized: {apply_spacy_lemmatization(test_text)}\")\n",
    "\n",
    "# lets apply to reviews\n",
    "review_df['Review'] = review_df['Review'].apply(apply_spacy_lemmatization)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c92714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent experience service org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrible experience flight like fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing experience service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience average staff horrible really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>excellent experience experience literally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>bag terrible staff annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>see loudly ad staff bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>see awesome staff excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>find crew annoying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Review\n",
       "0             excellent experience service org\n",
       "1         horrible experience flight like fuck\n",
       "2                   amazing experience service\n",
       "3                                    see awful\n",
       "4     experience average staff horrible really\n",
       "..                                         ...\n",
       "995  excellent experience experience literally\n",
       "996                bag terrible staff annoying\n",
       "997                    see loudly ad staff bad\n",
       "998                see awesome staff excellent\n",
       "999                         find crew annoying\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220f493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to processed_reviews.csv\n",
      "Saved to processed_reviews.json\n",
      "Saved comparison to review_comparison.csv\n",
      "\n",
      "Final processed data preview:\n",
      "Shape: (1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent experience service org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrible experience flight like fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing experience service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience average staff horrible really</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Review\n",
       "0          excellent experience service org\n",
       "1      horrible experience flight like fuck\n",
       "2                amazing experience service\n",
       "3                                 see awful\n",
       "4  experience average staff horrible really"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Exporting to CSV as it is kinda recommended for sentiment analysis so yeahh\n",
    "review_df.to_csv('processed_reviews.csv', index=False)\n",
    "print(\"Saved to processed_reviews.csv\")\n",
    "\n",
    "# Exporting to JSON as needed for APIs and web apps like Flask, FastAPI, Django\n",
    "review_df.to_json('processed_reviews.json', orient='records', indent=2)\n",
    "print(\"Saved to processed_reviews.json\")\n",
    "\n",
    "# Exporting both original and processed for comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Original_Review': df['Review'],\n",
    "    'Processed_Review': review_df['Review']\n",
    "})\n",
    "comparison_df.to_csv('review_comparison.csv', index=False)\n",
    "print(\"Saved comparison to review_comparison.csv\")\n",
    "\n",
    "print(\"\\nFinal processed data preview:\")\n",
    "print(f\"Shape: {review_df.shape}\")\n",
    "review_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
